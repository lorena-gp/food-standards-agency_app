{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.stats.proportion as smp\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to recode values (as on survey dataset)\n",
    "  \n",
    "# Create a dictionary of question names\n",
    "questions_dict_path = 'https://raw.githubusercontent.com/lorena-gp/food-standards-agency/master/survey_guide_variables.csv'\n",
    "questions_dict = pd.read_csv(questions_dict_path)\n",
    "questions_dict = pd.Series(questions_dict.Label.values, index=questions_dict.Variable).to_dict()\n",
    "\n",
    "# Create a nested dictionary of answer names\n",
    "answers_dict_path = 'https://raw.githubusercontent.com/lorena-gp/food-standards-agency/master/survey_guide_values.csv'\n",
    "answers_dict = pd.read_csv(answers_dict_path)\n",
    "answers_dict['Label'] = (answers_dict['Label']\n",
    "                         .replace({'Wave 1':2010, 'Wave 2':2012, 'Wave 3':2014, 'Wave 4':2016, 'Wave 5':2018})\n",
    "                         .replace({'Married/Civil Partnership/Living with Partner':'Married/Partnership'})\n",
    "                         .replace({'Single/Widowed/Divorced/Separated/Other':'Single/Other'}))\n",
    "answers_dict = answers_dict.fillna(method='ffill')\n",
    "answers_dict = answers_dict.groupby('Variable')[['Vlue', 'Label']].apply(lambda g: dict(g.values)).to_dict()\n",
    "answers_dict['wimd_2014_quintile'] = {1: 1, 2: 2, # 1 is most deprived\n",
    "                                      3: 3, 4: 4, 5: 5, # 5 is least deprived\n",
    "                                      -8: \"Don't know\", -1:'Not applicable'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Food and You survey dataset\n",
    "survey_path = 'https://raw.githubusercontent.com/lorena-gp/food-standards-agency/master/survey.csv'\n",
    "survey_full_dataset = pd.read_csv(survey_path)\n",
    "survey_full_dataset = pd.DataFrame(survey_full_dataset)\n",
    "\n",
    "# Encode 'Not applicable', 'Refused' and 'Don't know' as NaN\n",
    "survey_full_dataset = survey_full_dataset.replace([-9, -8, -1, 98], np.nan)\n",
    "cols_5_NaN = ['q4_1_4', 'q4_1_5a', 'Q4_1_5_comb', 'q4_1_6', 'q4_1_7', 'q4_1_8a', 'q4_1_8b', 'sanspray', 'q4_1_11',\n",
    "              'q4_1_12', 'q4_1_13', 'q4_1_14', 'q4_1_15', 'q4_1_16', 'q4_1_17', 'q4_1_18', 'q4_1_19']\n",
    "survey_full_dataset[cols_5_NaN] = survey_full_dataset[cols_5_NaN].replace([5], np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Define demographic variables of interest\n",
    "demographic_variables = ['age_dv', 'marstat2', 'religion_dv', 'RespSex', 'wimd_2014_quintile', 'workstat2', 'Q6_1']\n",
    "\n",
    "# To plot the survey answers (wave 4 and 5 only) for subpopulation groups for specified relevant questions\n",
    "waves = [4,5]\n",
    "survey_subpopulation = survey_full_dataset.loc[survey_full_dataset['surveyyear'].isin(waves)]\n",
    "survey_subpopulation[demographic_variables] = survey_subpopulation[demographic_variables].replace(answers_dict)\n",
    "\n",
    "# Combine demographics as desired, for example:\n",
    "survey_subpopulation['combined_demographics'] = (survey_subpopulation['workstat2'] + '_' +\n",
    "                                                 survey_subpopulation['RespSex'] + '_' +\n",
    "                                                 survey_subpopulation['marstat2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6588a961c48b47679c76f06c084dbf73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='question', options=('(D) Use any antibacterial surface sanitising …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define questions of interest\n",
    "questions_of_interest = ['sanspray', 'q4_1_6', 'q4_1_7', 'q4_1_8a', 'q4_1_8b',   'Q4_37', 'Q4_38',\n",
    "                         'bpoison', 'Q4_26b', 'Q4_19b', 'Q4_1_5_comb', 'eatoutev', 'fdsecst'] # etc\n",
    "\n",
    "questions_of_interest_names = questions_of_interest.copy()\n",
    "questions_of_interest_names[:] = [questions_dict.get(e,'') for e in questions_of_interest_names]\n",
    "\n",
    "questions_dict_inv = {v: k for k, v in questions_dict.items()}\n",
    "\n",
    "@interact\n",
    "def plot(\n",
    "    # provide an argument which has a default value\n",
    "    # consisting of a list of values\n",
    "    question=questions_of_interest_names\n",
    "):\n",
    "    temp = survey_subpopulation.copy()\n",
    "    \n",
    "    question = questions_dict_inv.get(question)\n",
    "    \n",
    "    temp = temp[temp['workstat2'] != 'Other'] \n",
    "\n",
    "    # Group according to the features of interest and calculate the % of answer types for the main question\n",
    "    temp = temp.groupby(['combined_demographics', question])[question].agg(['count'])\n",
    "    temp['total'] = temp.groupby('combined_demographics')['count'].transform('sum')\n",
    "    lower, upper = smp.proportion_confint (temp['count'], temp['total'], alpha=0.05, method='normal')\n",
    "    temp['CI_prop_upper'] = upper\n",
    "    temp['CI_prop_lower'] = lower\n",
    "    temp[question + ' (%)'] = temp['count'] / temp['total'] * 100\n",
    "    temp['CI_perc_upper'] = temp['CI_prop_upper'] * 100\n",
    "    temp['CI_perc_lower'] = temp['CI_prop_lower'] * 100\n",
    "    temp['abs_err'] = temp[question + ' (%)'] - temp['CI_perc_lower']\n",
    "    temp.reset_index(inplace=True) # To 'undo' the grouping\n",
    "    temp = temp.round(1)\n",
    "\n",
    "    # Recode the answers of the question of interest\n",
    "    temp = temp.replace(answers_dict)\n",
    "\n",
    "    abs_err = temp.pivot(index=question, columns='combined_demographics', values='abs_err')\n",
    "        \n",
    "    fig = temp.pivot(index=question, columns='combined_demographics', values=question +' (%)')\\\n",
    "          .plot(kind='barh', xerr=abs_err, width=0.75, figsize=(6,10))\n",
    "    for item in ([fig.title, fig.xaxis.label, fig.yaxis.label] + fig.get_xticklabels() + fig.get_yticklabels()):\n",
    "        item.set_fontsize(16)\n",
    "    plt.title(questions_dict.get(question), x =0,  fontsize = 16)\n",
    "    plt.xlabel(question + ' (%)')\n",
    "    plt.ylabel('')\n",
    "    fig.legend(loc='center left', bbox_to_anchor=(1.2, 0.8), fontsize = 14)\n",
    "    plt.xlim(0, max(temp[question +' (%)'] + 10))\n",
    "    fig.spines['top'].set_visible(False)\n",
    "    fig.spines['right'].set_visible(False)\n",
    "    fig.spines['left'].set_visible(False)\n",
    "\n",
    "    # To plot the % number\n",
    "    for p in fig.patches:\n",
    "        width, height = p.get_width(), p.get_height()\n",
    "        x, y = p.get_xy() \n",
    "        fig.annotate('{:}%'.format(width), (x + width + 8, y + 0.03), fontsize = 14)\n",
    "\n",
    "\n",
    "# To show this as an independent (local) dashboard with Voila (https://github.com/voila-dashboards/voila):\n",
    "# Install in terminal by: conda install -c conda-forge voila\n",
    "# Start Voilà locally (cd in directory with this notebook) by running: voila Food-and-You-survey_risks.ipynb\n",
    "\n",
    "\n",
    "# To give access to voila dashboard remotely using github and binder:\n",
    "# Set up a public github repo with all data files needed (as csv),\n",
    "# jupyter notebook with widgets(in which all csv files are read using the raw URLs from github)\n",
    "# and a requirements.txt (listing  all the modules needed to run the notebook).\n",
    "# Use binder (https://mybinder.org) and specify the path of the jupypter notebook (using voila/render),\n",
    "# indicate it is a URL path.\n",
    "# The new URL generated can be shared and is available any time.\n",
    "\n",
    "\n",
    "# To give access to voila dashboard remotely using ngrok:\n",
    "# (see https://voila.readthedocs.io/en/stable/deploy.html#sharing-voila-applications-with-ngrok)\n",
    "# Install ngrok: https://ngrok.com/download, unzip file and, if using macOS, move executable file to /usr/local/bin\n",
    "# Start Voilà locally (cd in directory with this notebook) by running: voila Food-and-You-survey_risks.ipynb\n",
    "# In a new terminal window, start ngrok by running: ngrok http 8866 (check local host number actually used by\n",
    "# the dashboard of interest, as, if running voila multiple times, this number will change)\n",
    "# Copy the link from the ngrok terminal window (link looks like https://8bb6fded.ngrok.io) and use or send link.\n",
    "# Website will take some time to load, as the jupyter noteook is running in the background.\n",
    "# When using the ngrok link, the requests will be forwared to your local instance of Voilà.\n",
    "\n",
    "# Census data is too heavy and cannot be ploted as a voula dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
